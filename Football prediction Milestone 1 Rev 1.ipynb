{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of df columns : 62\n",
      "Number of df columns : 62\n",
      "Number of df columns : 62\n",
      "Number of df columns : 62\n",
      "Number of df columns : 62\n",
      "Number of df columns : 62\n",
      "Number of df columns : 62\n",
      "Number of df columns : 62\n",
      "Number of df columns : 62\n",
      "Number of df columns : 62\n",
      "    Div        Date      HomeTeam        AwayTeam  FTHG  FTAG FTR  ...    GBA   BSH   BSD    BSA   SBH   SBD    SBA\n",
      "0    E0  10/08/2018    Man United       Leicester     2     1   H  ...    NaN   NaN   NaN    NaN   NaN   NaN    NaN\n",
      "1    E0  11/08/2018   Bournemouth         Cardiff     2     0   H  ...    NaN   NaN   NaN    NaN   NaN   NaN    NaN\n",
      "2    E0  11/08/2018        Fulham  Crystal Palace     0     2   A  ...    NaN   NaN   NaN    NaN   NaN   NaN    NaN\n",
      "3    E0  11/08/2018  Huddersfield         Chelsea     0     3   A  ...    NaN   NaN   NaN    NaN   NaN   NaN    NaN\n",
      "4    E0  11/08/2018     Newcastle       Tottenham     1     2   A  ...    NaN   NaN   NaN    NaN   NaN   NaN    NaN\n",
      "..   ..         ...           ...             ...   ...   ...  ..  ...    ...   ...   ...    ...   ...   ...    ...\n",
      "375  E0    09/05/10       Everton      Portsmouth     1     0   H  ...   9.00  1.30  5.00  10.00  1.29  5.00   8.50\n",
      "376  E0    09/05/10          Hull       Liverpool     0     0   D  ...   1.55  6.00  3.75   1.57  6.00  3.75   1.50\n",
      "377  E0    09/05/10    Man United           Stoke     4     0   H  ...  19.00  1.11  7.50  23.00  1.11  7.50  15.00\n",
      "378  E0    09/05/10      West Ham        Man City     1     1   D  ...   1.90  4.20  3.60   1.80  4.00  3.40   1.80\n",
      "379  E0    09/05/10        Wolves      Sunderland     2     1   H  ...   2.90  2.38  3.25   3.00  2.25  3.20   2.88\n",
      "\n",
      "[3800 rows x 77 columns]\n",
      "0      2020-08-10\n",
      "1      2020-08-11\n",
      "2      2020-08-11\n",
      "3      2020-08-11\n",
      "4      2020-08-11\n",
      "          ...    \n",
      "375    2010-05-09\n",
      "376    2010-05-09\n",
      "377    2010-05-09\n",
      "378    2010-05-09\n",
      "379    2010-05-09\n",
      "Name: Date, Length: 3800, dtype: object\n",
      "['Everton' 'Aston Villa' 'Blackburn' 'Bolton' 'Chelsea' 'Portsmouth'\n",
      " 'Stoke' 'Wolves' 'Tottenham' 'Man United' 'Sunderland' 'Wigan'\n",
      " 'Birmingham' 'Burnley' 'Hull' 'Liverpool' 'Arsenal' 'Man City' 'Fulham'\n",
      " 'West Ham' 'West Brom' 'Newcastle' 'Blackpool' 'QPR' 'Swansea' 'Norwich'\n",
      " 'Reading' 'Southampton' 'Crystal Palace' 'Cardiff' 'Leicester'\n",
      " 'Bournemouth' 'Watford' 'Middlesbrough' 'Brighton' 'Huddersfield']\n",
      "[2008 2009 2010 2011 2012 2013 2014 2015 2016 2019 2020]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amada\\pycharmprojects\\cs230dlproject\\venv\\lib\\site-packages\\pandas\\core\\generic.py:5303: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n",
      "c:\\users\\amada\\pycharmprojects\\cs230dlproject\\venv\\lib\\site-packages\\ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3800 entries, 0 to 3799\n",
      "Data columns (total 41 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Date         3800 non-null   object \n",
      " 1   HomeTeam     3800 non-null   object \n",
      " 2   AwayTeam     3800 non-null   object \n",
      " 3   FTHG         3800 non-null   int64  \n",
      " 4   FTAG         3800 non-null   int64  \n",
      " 5   FTR          3800 non-null   object \n",
      " 6   HTAG         3800 non-null   int64  \n",
      " 7   matchID      3800 non-null   int64  \n",
      " 8   Season       3800 non-null   int64  \n",
      " 9   HomeTeamDay  3800 non-null   int64  \n",
      " 10  AwayTeamDay  3800 non-null   int64  \n",
      " 11  HW           3800 non-null   int64  \n",
      " 12  AW           3800 non-null   int64  \n",
      " 13  D            3800 non-null   int64  \n",
      " 14  HR           3800 non-null   object \n",
      " 15  AR           3800 non-null   object \n",
      " 16  ordinalHR    3800 non-null   float64\n",
      " 17  1_last_HTR   3783 non-null   object \n",
      " 18  2_last_HTR   3765 non-null   object \n",
      " 19  3_last_HTR   3746 non-null   object \n",
      " 20  1_last_ATR   3781 non-null   object \n",
      " 21  2_last_ATR   3763 non-null   object \n",
      " 22  3_last_ATR   3746 non-null   object \n",
      " 23  1_last_HTHR  3764 non-null   object \n",
      " 24  2_last_HTHR  3728 non-null   object \n",
      " 25  1_last_ATAR  3764 non-null   object \n",
      " 26  2_last_ATAR  3728 non-null   object \n",
      " 27  7_HTW_rate   3710 non-null   float64\n",
      " 28  12_HTW_rate  3656 non-null   float64\n",
      " 29  7_ATW_rate   3710 non-null   float64\n",
      " 30  12_ATW_rate  3656 non-null   float64\n",
      " 31  7_HTD_rate   3710 non-null   float64\n",
      " 32  12_HTD_rate  3656 non-null   float64\n",
      " 33  7_ATD_rate   3710 non-null   float64\n",
      " 34  12_ATD_rate  3656 non-null   float64\n",
      " 35  5_HTHW_rate  3692 non-null   float64\n",
      " 36  5_ATAW_rate  3692 non-null   float64\n",
      " 37  7_HTL_rate   3710 non-null   float64\n",
      " 38  12_HTL_rate  3710 non-null   float64\n",
      " 39  7_ATL_rate   3710 non-null   float64\n",
      " 40  12_ATL_rate  3710 non-null   float64\n",
      "dtypes: float64(15), int64(10), object(16)\n",
      "memory usage: 1.2+ MB\n",
      "     HR\n",
      "0     L\n",
      "1     L\n",
      "2     L\n",
      "3     L\n",
      "4     W\n",
      "...  ..\n",
      "3795  W\n",
      "3796  W\n",
      "3797  D\n",
      "3798  D\n",
      "3799  D\n",
      "\n",
      "[3800 rows x 1 columns]\n",
      "Xtrain shape:  (2850, 74) Xtest shape:  (950, 74)\n",
      "[ 2.74977339e-03 -1.33087079e+01 -3.77320786e-01  1.83761305e-01\n",
      " -1.37380443e-01  7.38403033e-02  1.07194046e-01  1.12360398e-01\n",
      "  1.05050308e-01  0.00000000e+00  8.23530682e-02  9.59062492e-02\n",
      " -4.17494172e-01  2.96955990e-01 -1.59183917e-01  6.73162634e-02\n",
      "  0.00000000e+00  1.65623264e-01 -1.02292395e-01 -2.51493926e-01\n",
      " -4.07190383e-01 -3.34649764e-01  7.81290581e-02  4.42485326e-02\n",
      "  4.09705314e-02  1.75594996e-01  1.44540434e-01  6.05705234e-03\n",
      " -4.08263204e-02 -3.98070613e-02  1.13859985e-01  3.82813695e-02\n",
      " -2.52008440e-01  5.21966105e-02  1.15052215e-01  6.40600343e-02\n",
      "  1.14011628e-01  2.39907029e-01  3.50588536e-01 -3.74141982e-02\n",
      " -7.85005399e-02 -1.56108889e-01  1.03539666e-02 -6.18669444e-02\n",
      "  5.40710877e-03  0.00000000e+00 -1.82342790e-01 -8.53486857e-02\n",
      "  3.42303350e-01  3.31591101e-02  5.10807537e-02 -1.53759790e-01\n",
      "  0.00000000e+00 -2.44120792e-01  7.37307700e-02  2.35584682e-01\n",
      "  3.27974155e-01  3.60299643e-01 -6.91581710e-02 -4.98565238e-02\n",
      " -1.58766490e-01 -9.00781160e-02 -1.63659313e-01 -6.50172996e-02\n",
      "  7.09692030e-02 -1.10127274e-01 -1.20970566e-01 -2.80662741e-02\n",
      "  2.90030207e-01  2.64026431e-02 -5.27073296e-03 -1.51107634e-01\n",
      " -2.95479779e-02 -1.39172065e-01]\n",
      "Train Score:  1.0\n",
      "Test Score:  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\amada\\pycharmprojects\\cs230dlproject\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#import needed Python libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#graphics parameters of the notebook\n",
    "# display graphs inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Make graphs prettier\n",
    "pd.set_option('display.max_columns', 15)\n",
    "pd.set_option('display.width', 400)\n",
    "pd.set_option('plotting.matplotlib.register_converters', True)\n",
    "\n",
    "# Make the fonts bigger\n",
    "plt.rc('figure', figsize=(14, 7))\n",
    "plt.rc('font', family='normal', weight='bold', size=15)\n",
    "\n",
    "#inegrate data from 2009-2010 to 2018-2019 seasons from different files\n",
    "data_18_19 = pd.read_csv(\"./data/2018_2019.csv\", parse_dates=True)\n",
    "data_17_18 = pd.read_csv(\"./data/2017_2018.csv\", parse_dates=True)\n",
    "data_16_17 = pd.read_csv(\"./data/2016_2017.csv\", parse_dates=True)\n",
    "data_15_16 = pd.read_csv(\"./data/2015_2016.csv\", parse_dates=True)\n",
    "data_14_15 = pd.read_csv(\"./data/2014_2015.csv\", parse_dates=True)\n",
    "data_13_14 = pd.read_csv(\"./data/2013_2014.csv\", parse_dates=True)\n",
    "data_12_13 = pd.read_csv(\"./data/2012_2013.csv\", parse_dates=True)\n",
    "data_11_12 = pd.read_csv(\"./data/2011_2012.csv\", parse_dates=True)\n",
    "data_10_11 = pd.read_csv(\"./data/2010_2011.csv\", parse_dates=True)\n",
    "data_09_10 = pd.read_csv(\"./data/2009_2010.csv\", parse_dates=True)\n",
    "\n",
    "\n",
    "#test about data consistency for all files\n",
    "for df in [data_18_19, data_17_18, data_16_17, data_15_16, data_14_15, data_13_14, data_12_13, data_11_12, data_10_11, data_09_10]:\n",
    "    print(\"Number of df columns : \" + str(len(data_18_19.columns)))\n",
    "\n",
    "#integrate data in a single df\n",
    "raw_data = pd.concat([data_18_19, data_17_18, data_16_17, data_15_16, data_14_15, data_13_14, data_12_13, data_11_12, data_10_11, data_09_10])\n",
    "\n",
    "print(raw_data)\n",
    "\n",
    "#Select useful features for data visualization and analysis purposes\n",
    "E0_data = raw_data[[\"Date\", \"HomeTeam\", \"AwayTeam\", \"FTHG\", \"FTAG\", \"FTR\", \"HTAG\"]]\n",
    "\n",
    "#convert date format to YYYY-MM-DD classic format\n",
    "E0_data.Date = E0_data.Date.map(lambda x : \"20\" + x[6:8] + \"-\" + x[3:5] + \"-\" + x[0:2])\n",
    "print(E0_data.Date)\n",
    "#sort data by date\n",
    "E0_data.sort_values('Date', inplace=True)\n",
    "\n",
    "#reset data indexes\n",
    "E0_data = E0_data.reset_index(drop=True)\n",
    "\n",
    "#create matchID column\n",
    "E0_data['matchID'] = E0_data.index\n",
    "\n",
    "#create season feature\n",
    "E0_data['Season'] = 0\n",
    "E0_data.Season = E0_data.Date.map(lambda x : int(x[0:4]) if int(x[5:7]) > 11 else int(x[0:4]) - 1)\n",
    "\n",
    "#null values test\n",
    "E0_data.isnull().any()\n",
    "\n",
    "#create teams list\n",
    "teams = E0_data['HomeTeam'].unique()\n",
    "print(teams)\n",
    "\n",
    "#create seasons list\n",
    "seasons = np.sort(E0_data['Season'].unique())\n",
    "print(seasons)\n",
    "\n",
    "#match day feature construction for HomeTeam and AwayTeam (1st match of a season --> 1, last --> 38 because 20 team play by season)\n",
    "E0_HT_grpby = E0_data.groupby('HomeTeam')[['Date']]\n",
    "E0_AT_grpby = E0_data.groupby('AwayTeam')[['Date']]\n",
    "\n",
    "def fxyH(row):\n",
    "    x = row['HomeTeam']\n",
    "    y = row['Date']\n",
    "    df1 = E0_HT_grpby.get_group(x)\n",
    "    df2 = E0_AT_grpby.get_group(x)\n",
    "    df1 = df1[df1['Date'] < y]\n",
    "    df2 = df2[df2['Date'] < y]\n",
    "    day = (1 + len(df1) + len(df2)) % 38\n",
    "    return 38 if day == 0 else day \n",
    "\n",
    "def fxyA(row):\n",
    "    x = row['AwayTeam']\n",
    "    y = row['Date']\n",
    "    df1 = E0_HT_grpby.get_group(x)\n",
    "    df2 = E0_AT_grpby.get_group(x)\n",
    "    df1 = df1[df1['Date'] < y]\n",
    "    df2 = df2[df2['Date'] < y]\n",
    "    day = (1 + len(df1) + len(df2)) % 38\n",
    "    return 38 if day == 0 else day \n",
    "\n",
    "E0_data['HomeTeamDay'] = E0_data.apply(fxyH, axis=1)\n",
    "E0_data['AwayTeamDay'] = E0_data.apply(fxyA, axis=1)\n",
    "\n",
    "def resultConverter(A):\n",
    "    if A == 'H':\n",
    "        return 'W'\n",
    "    elif A =='A':\n",
    "        return 'L'\n",
    "    else:\n",
    "        return 'D'\n",
    "\n",
    "def resultInverser(A):\n",
    "    if A == 'W':\n",
    "        return 'L'\n",
    "    elif A == 'L':\n",
    "        return 'W'\n",
    "    else:\n",
    "        return 'D'\n",
    "def ordinalResultConverter(A):\n",
    "    if A == 'W':\n",
    "        return 1\n",
    "    elif A == 'L':\n",
    "        return 0\n",
    "    else:\n",
    "        return 0.5\n",
    "    \n",
    "    #make dummies variables for FTR (result of match), HW = Home Win, AW = Away Win, D = draw\n",
    "E0_data['HW'] = E0_data.FTR.map(lambda x : 1 if x == 'H' else 0)\n",
    "E0_data['AW'] = E0_data.FTR.map(lambda x : 1 if x == 'A' else 0)\n",
    "E0_data['D']= E0_data.FTR.map(lambda x : 1 if x == 'D' else 0)\n",
    "\n",
    "#make 2 different variable for the result of a match : 1 for the home team point of view, the other for the away team pt of view\n",
    "E0_data['HR'] = E0_data.FTR.map(lambda x : resultConverter(x))\n",
    "E0_data['AR'] = E0_data.HR.map(lambda x : resultInverser(x))\n",
    "\n",
    "#make ordinal variable for the home team point of view result (1 = win, 0.5 = Draw, 0 = loss)\n",
    "E0_data['ordinalHR'] = E0_data.HR.map(lambda x : ordinalResultConverter(x))\n",
    "\n",
    "\n",
    "grp_by_HT = E0_data.groupby('HomeTeam')\n",
    "grp_by_AT = E0_data.groupby('AwayTeam')\n",
    "\n",
    "#past performance features engineering\n",
    "for team in teams:\n",
    "    \n",
    "    #we retrieve results series of the team\n",
    "    teamHomeResults_s = grp_by_HT.get_group(team)['HR']\n",
    "    teamAwayResults_s = grp_by_AT.get_group(team)['AR']\n",
    "    #combine these 2 series and sort the obtained serie\n",
    "    teamResults_s = pd.concat([teamHomeResults_s, teamAwayResults_s]).sort_index()\n",
    "\n",
    "    #(i) compute k_last_HR and k_last_AR --> 6 features\n",
    "    lag1TeamResults_d = teamResults_s.shift(1).to_dict()\n",
    "    lag2TeamResults_d = teamResults_s.shift(2).to_dict()\n",
    "    lag3TeamResults_d = teamResults_s.shift(3).to_dict()\n",
    "    \n",
    "    #k_last_HTR and k_last_ATR are just shifted versions of the results series\n",
    "    E0_data.loc[teamHomeResults_s.index,'1_last_HTR'] = E0_data.loc[teamHomeResults_s.index,:].index.map(lambda x : lag1TeamResults_d[x])\n",
    "    E0_data.loc[teamHomeResults_s.index,'2_last_HTR'] = E0_data.loc[teamHomeResults_s.index,:].index.map(lambda x : lag2TeamResults_d[x])\n",
    "    E0_data.loc[teamHomeResults_s.index,'3_last_HTR'] = E0_data.loc[teamHomeResults_s.index,:].index.map(lambda x : lag3TeamResults_d[x])\n",
    "    E0_data.loc[teamAwayResults_s.index,'1_last_ATR'] = E0_data.loc[teamAwayResults_s.index,:].index.map(lambda x : lag1TeamResults_d[x])\n",
    "    E0_data.loc[teamAwayResults_s.index,'2_last_ATR'] = E0_data.loc[teamAwayResults_s.index,:].index.map(lambda x : lag2TeamResults_d[x])\n",
    "    E0_data.loc[teamAwayResults_s.index,'3_last_ATR'] = E0_data.loc[teamAwayResults_s.index,:].index.map(lambda x : lag3TeamResults_d[x])\n",
    "    \n",
    "    #(ii) Compute k_last_HTRH and k_last ATAR --> 4 features\n",
    "    #we need here to diferentiate home results and past results. Python dictionaries allows the program to access to\n",
    "    #needed data faster than with a Pandas serie\n",
    "    lag1TeamHomeResults_d = teamHomeResults_s.shift(1).to_dict()\n",
    "    lag2TeamHomeResults_d = teamHomeResults_s.shift(2).to_dict()\n",
    "    lag1TeamAwayResults_d = teamAwayResults_s.shift(1).to_dict()\n",
    "    lag2TeamAwayResults_d = teamAwayResults_s.shift(2).to_dict()\n",
    "    \n",
    "    E0_data.loc[teamHomeResults_s.index,'1_last_HTHR'] = E0_data.loc[teamHomeResults_s.index,:].index.map(lambda x : lag1TeamHomeResults_d[x])\n",
    "    E0_data.loc[teamHomeResults_s.index,'2_last_HTHR'] = E0_data.loc[teamHomeResults_s.index,:].index.map(lambda x : lag2TeamHomeResults_d[x])\n",
    "    E0_data.loc[teamAwayResults_s.index,'1_last_ATAR'] = E0_data.loc[teamAwayResults_s.index,:].index.map(lambda x : lag1TeamAwayResults_d[x])\n",
    "    E0_data.loc[teamAwayResults_s.index,'2_last_ATAR'] = E0_data.loc[teamAwayResults_s.index,:].index.map(lambda x : lag2TeamAwayResults_d[x])\n",
    "    \n",
    "    #(iii) rates based features : we need to get only season specific results series (to avoid taking previous season results into season rates)\n",
    "    for season in seasons:\n",
    "        \n",
    "        #retrieve season specific results serie (1 win serie, 1 draw serie the loss  will be computed thanks to\n",
    "        #the 2 others)\n",
    "        teamHomeResultsW_s = grp_by_HT.get_group(team)['HW']\n",
    "        teamAwayResultsW_s = grp_by_AT.get_group(team)['AW']\n",
    "        teamResultsW_s = pd.concat([teamHomeResultsW_s, teamAwayResultsW_s]).sort_index()\n",
    "\n",
    "        teamHomeResultsD_s = grp_by_HT.get_group(team)['D']\n",
    "        teamAwayResultsD_s = grp_by_AT.get_group(team)['D']\n",
    "        teamResultsD_s = pd.concat([teamHomeResultsD_s, teamAwayResultsD_s]).sort_index()\n",
    "        \n",
    "        #(i) compute 7_HTW_rate, 12_HTW_rate, 7_HTD_rate, 12_HTD_rate, 7_ATW_rate, 12_ATW_rate, 7_ATD_rate, 12_ATD_rate --> 8 features\n",
    "        win7TeamResultsW_d = teamResultsW_s.shift(1).rolling(window = 7, min_periods = 5).mean().to_dict()\n",
    "        win12TeamResultsW_d = teamResultsW_s.shift(1).rolling(window = 12, min_periods = 8).mean().to_dict()\n",
    "        win7TeamResultsD_d = teamResultsD_s.shift(1).rolling( window = 7, min_periods = 5).mean().to_dict()\n",
    "        win12TeamResultsD_d = teamResultsD_s.shift(1).rolling( window = 12, min_periods = 8).mean().to_dict()\n",
    "        \n",
    "        E0_data.loc[teamHomeResultsW_s.index,'7_HTW_rate'] = E0_data.loc[teamHomeResultsW_s.index,:].index.map(lambda x : win7TeamResultsW_d[x])\n",
    "        E0_data.loc[teamHomeResultsW_s.index,'12_HTW_rate'] = E0_data.loc[teamHomeResultsW_s.index,:].index.map(lambda x : win12TeamResultsW_d[x])\n",
    "        E0_data.loc[teamAwayResultsW_s.index,'7_ATW_rate'] = E0_data.loc[teamAwayResultsW_s.index,:].index.map(lambda x : win7TeamResultsW_d[x])\n",
    "        E0_data.loc[teamAwayResultsW_s.index,'12_ATW_rate'] = E0_data.loc[teamAwayResultsW_s.index,:].index.map(lambda x : win12TeamResultsW_d[x])\n",
    "        \n",
    "        E0_data.loc[teamHomeResultsD_s.index,'7_HTD_rate'] = E0_data.loc[teamHomeResultsD_s.index,:].index.map(lambda x : win7TeamResultsD_d[x])\n",
    "        E0_data.loc[teamHomeResultsD_s.index,'12_HTD_rate'] = E0_data.loc[teamHomeResultsD_s.index,:].index.map(lambda x : win12TeamResultsD_d[x])\n",
    "        E0_data.loc[teamAwayResultsD_s.index,'7_ATD_rate'] = E0_data.loc[teamAwayResultsD_s.index,:].index.map(lambda x : win7TeamResultsD_d[x])\n",
    "        E0_data.loc[teamAwayResultsD_s.index,'12_ATD_rate'] = E0_data.loc[teamAwayResultsD_s.index,:].index.map(lambda x : win12TeamResultsD_d[x])\n",
    "\n",
    "        #(ii) compute 5_HTHW_rate and 5_ATAW_rate\n",
    "        win5TeamResultsHomeW_d = teamHomeResultsW_s.shift(1).rolling( window = 5, min_periods = 3).mean().to_dict()\n",
    "        win5TeamResultsAwayW_d = teamAwayResultsW_s.shift(1).rolling( window = 5, min_periods = 3).mean().to_dict()\n",
    "        E0_data.loc[teamHomeResultsW_s.index,'5_HTHW_rate'] = E0_data.loc[teamHomeResultsW_s.index,:].index.map(lambda x : win5TeamResultsHomeW_d[x])\n",
    "        E0_data.loc[teamAwayResultsW_s.index,'5_ATAW_rate'] = E0_data.loc[teamAwayResultsW_s.index,:].index.map(lambda x : win5TeamResultsAwayW_d[x])\n",
    "\n",
    "#compute missing features k_XTL_rate thanks to the k_XTW_rate and k_XTD_rate features\n",
    "E0_data.loc[:,'7_HTL_rate'] = 1 - (E0_data['7_HTW_rate'] + E0_data['7_HTD_rate'])\n",
    "E0_data.loc[:,'12_HTL_rate'] = 1 - (E0_data['7_HTW_rate'] + E0_data['7_HTD_rate'])\n",
    "E0_data.loc[:,'7_ATL_rate'] = 1 - (E0_data['7_ATW_rate'] + E0_data['7_ATD_rate'])\n",
    "E0_data.loc[:,'12_ATL_rate'] = 1 - (E0_data['7_ATW_rate'] + E0_data['7_ATD_rate'])\n",
    "\n",
    "\n",
    "#Create X and Y\n",
    "X = pd.get_dummies(E0_data[['HomeTeam', 'AwayTeam', 'Season', 'ordinalHR']])\n",
    "Y = E0_data[['FTR']]\n",
    "\n",
    "#Split X and Y into training and Test Sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, shuffle=False)\n",
    "print(\"Xtrain shape: \", x_train.shape, \"Xtest shape: \", x_test.shape)\n",
    "\n",
    "#Setup the model\n",
    "model = LogisticRegression(C=1)\n",
    "\n",
    "#Train the Model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "#Coefficient Check\n",
    "coef = model.coef_[0]\n",
    "print (coef)\n",
    "\n",
    "#Model Score\n",
    "print(\"Train Score: \", model.score(x_train, y_train))\n",
    "print(\"Test Score: \", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}